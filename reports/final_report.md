# Технічний звіт: Класифікація грибів (Baseline vs AutoML)

## 1. Вступ
Метою цього проекту була побудова класифікатора для визначення їстівності грибів (Mushroom Dataset) із застосуванням MLOps практик. Ключовим викликом було забезпечення відтворюваності експериментів та усунення "витоку даних" (Data Leakage).

В ході роботи було проведено три ітерації експериментів: від ручного Baseline до оптимізованого AutoML пошуку.

## 2. Зведена таблиця результатів (Summary)

Нижче наведено порівняння трьох підходів. Усі моделі навчалися на даних **без колонки `odor`** (щоб уникнути тривіальної класифікації).

| Підхід | Алгоритм (Модель) | Accuracy | F1 Score (Macro) | Час навчання (Total) | Коментар |
| :--- | :--- | :---: | :---: | :---: | :--- |
| **Baseline** | Random Forest | **1.00** | 1.00 | ~2.5 сек | Ручне налаштування параметрів. |
| **AutoML (60s)**| **XGBoost** | **1.00** | 1.00 | 63.5 сек | Максимальний бюджет часу. Знайдено "важку" модель. |
| **AutoML (10s)**| **LightGBM** | **1.00** | 1.00 | **13.7 сек** | Екстремальний ліміт. Знайдено найефективнішу модель. |

> **Run ID в MLflow:** 561142289336798878

## 3. Аналіз результатів (Deep Dive)

### Чому всі моделі показали 100% точність?
Навіть після видалення "читерської" ознаки `odor` (запах), датасет грибів залишається відносно простим для сучасних алгоритмів.
* **Причина:** Класи грибів у цьому датасеті є *лінійно роздільними* або майже роздільними за комбінацією інших візуальних ознак.
* **Ключові ознаки:** Feature Importance показав, що модель ідеально розрізняє класи за `spore-print-color` (колір спор) та `gill-color` (колір пластинок).
* **Висновок:** Це не є помилкою перенавчання (overfitting), це властивість даних. Видалення `odor` зробило задачу чесною, але не неможливою.

### Ефективність AutoML vs Baseline
* **Baseline (Random Forest):** Вимагав написання коду для препроцесингу (LabelEncoder/OrdinalEncoder) та ручного вибору гіперпараметрів (`n_estimators`, `max_depth`).
* **AutoML (FLAML):**
    * **Ітерація 60с:** Знайшов XGBoost. Це потужний, але "важкий" алгоритм.
    * **Ітерація 10с:** Це найцікавіший момент. При обмеженні часу AutoML автоматично перемкнувся на **LightGBM**. Ця модель дала ту ж саму якість (1.0), але навчалася **у 5 разів швидше** (13.7с проти 63.5с).

**Висновок:** AutoML виявився корисним не для підвищення точності (вона і так максимальна), а для **оптимізації ресурсів**. Він знайшов легшу модель без участі людини.

## 4. Висновки та Рекомендації

### Data Leakage
Успішно ідентифіковано та усунуто витік даних через ознаку `odor`. Валідація через Feature Importance підтвердила, що моделі більше не спираються на запах, а використовують візуальні характеристики.

### Рекомендація для продакшну (Production Choice)
Для впровадження рекомендується використовувати модель **LightGBM (з ітерації AutoML 10s)**.

**Аргументація:**
1.  **Швидкість:** Вона найшвидша у навчанні та інференсі.
2.  **Якість:** Забезпечує 100% точність.
3.  **Ефективність:** Споживає менше пам'яті, ніж Random Forest (який зберігає великі дерева).

### Технічний стек
* **Tracking:** MLflow (локальний сервер).
* **Config Management:** Hydra (YAML конфігурації).
* **AutoML Engine:** FLAML.
* **Code Structure:** Cookiecutter Data Science (src/configs/data).