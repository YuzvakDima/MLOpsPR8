    Технічний Звіт: Класифікація Грибів (Mushroom Classification)
    Дата: 14.12.2025Автор: Senior MLOps EngineerСтатус: Завершено
1. Контекст Експерименту
    Метою проекту була побудова моделі класифікації грибів (їстівний/отруйний) з умовою суворого дотримання Reproducible Research.Критичною вимогою було усунення Data Leakage (витоку даних): ознака odor (запах) була видалена, оскільки вона є тривіальним предиктором, що унеможливлює реальне навчання моделі на візуальних патернах.
2. Зведена таблиця результатів (Summary)
    Порівняння ручного підходу (Baseline) та автоматизованого пошуку (AutoML).
   ХарактеристикаBaseline (Manual)AutoML (FLAML)
   АлгоритмRandom ForestXGBoost (Best Estimator)
   Accuracy1.0000 1.0000
   F1 Score (Macro)1.0000 1.0000
   ROC AUC 1.0000 1.0000
   Time Budget 0 с (миттєвий запуск) 60 с (обмеження)
   Фактичний час< 1 с (навчання) 63.5 с (пошук + навчання)
   Налаштування Ручні евристики Автоматична оптимізація
3. Глибинний аналіз (Deep Dive)
    Чому обидві моделі показали 100% точність?
    Навіть після видалення "лікуючої" ознаки odor, датасет залишається високо детермінованим. Це означає, що класи грибів у цій вибірці мають чіткі, неперетинні правила поділу за іншими ознаками.
   Feature Importance Analysis показав, що після видалення запаху, найважливішою ознакою стає spore-print-color (колір спор) та gill-color (колір пластинок).
   Алгоритми на основі дерев рішень (Random Forest та XGBoost) ідеально підходять для знаходження таких ієрархічних правил (наприклад: IF spore-print-color = green THEN poisonous), що і призвело до відсутності помилок на тестовій вибірці.
   Чи був корисним AutoML?
   Незважаючи на те, що Baseline досяг максимуму, використання FLAML (AutoML) було стратегічно важливим:
   Валідація результату: AutoML перебрав кілька сімейств алгоритмів (LGBM, XGBoost, ExtraTrees) і підтвердив, що результат 1.0 досягається стабільно різними методами, а не є випадковістю Random Forest.
   Оптимізація архітектури: FLAML обрав XGBoost. У порівнянні з Random Forest, градієнтний бустинг часто будує більш "легкі" моделі (менша глибина дерев), що позитивно впливає на швидкість роботи в продакшні.
4. Висновки та Рекомендації
   Data Leakage Strategy
   Видалення колонки odor було успішним. Ми довели, що модель здатна розрізняти гриби, спираючись виключно на фізичні/візуальні характеристики, що робить її більш надійною для реального застосування (де користувач може не мати можливості оцінити запах).
   Recommendation for Production
   Для впровадження в продакшн рекомендується використовувати модель AutoML (XGBoost).
   Аргументація:
   Швидкість інференсу (Inference Speed): XGBoost зазвичай швидший при формуванні передбачень, ніж Random Forest (який вимагає усереднення голосів від великої кількості глибоких дерев).
   Розмір моделі: Серіалізований об'єкт XGBoost часто займає менше пам'яті.
   Підтримка: XGBoost є індустріальним стандартом для табличних даних.
5. Наступні кроки (Optional)
   Для подальшого ускладнення завдання та тестування стійкості (Robustness) можна:
   Зменшити кількість доступних ознак до 5 випадкових.
   Додати штучний шум (Noise) у дані.